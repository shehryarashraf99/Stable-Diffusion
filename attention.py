import torch
from torch import nn
from torch.nn import functional as F
import math



## we will have to learn to code transformer architecture to make self attention class
class SelfAttention(nn.Module):
